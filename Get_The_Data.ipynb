{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c7540b",
   "metadata": {},
   "source": [
    "Import the libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96b7fd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m033\\Anaconda3\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.16) or chardet (3.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pyodbc\n",
    "pyodbc.drivers()\n",
    "\n",
    "from datetime import datetime\n",
    "import psutil\n",
    "\n",
    "# For the Yahoo Finance api\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "yf.pdr_override() # <== that's all it takes :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0328df7",
   "metadata": {},
   "source": [
    "Accessing the legacy Oracle database through a SQL Server linked server.  This is to cut down on intergration points.  The recent switch data will exist on SQl Server and a linked server exists on the same instance to the legacy Oracle data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42969f9",
   "metadata": {},
   "source": [
    "### Database connections and SQL to retrieve the various data needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b616bb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "2024-08-14 17:17:24.364670\n",
      "==========================\n",
      "svmem(total=16756752384, available=3971280896, percent=76.3, used=12785471488, free=3971280896)\n",
      "==========================\n",
      ".\\data\\iSuite_Product_list.csv\n"
     ]
    }
   ],
   "source": [
    "SQL_server = 'xxx\\yyy'\n",
    "Reporting_database = 'zzz'\n",
    "Reference_Data_database = 'aaa'\n",
    "\n",
    "pd.set_option('max_row', None)\n",
    "\n",
    "# Set a value for the home folder.\n",
    "home_folder = \".\"\n",
    "\n",
    "# Set values for the various paths.\n",
    "input_path = home_folder + \"\\data\"\n",
    "\n",
    "print('==========================')\n",
    "now = datetime.now()\n",
    "print(now)\n",
    "print('==========================')\n",
    "print(psutil.virtual_memory())\n",
    "print('==========================')\n",
    "\n",
    "filename = input_path + \"\\iSuite_Product_list.csv\"\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff676320",
   "metadata": {},
   "source": [
    "# 1. Get all iSuite policies that can have switchable funds.\n",
    "## - Start by determining what's the population of all policies that can possibly have a switch.\n",
    "##  - Get a list of products that have had a switch at some point.  \n",
    "## - This allows us to look for a list of all policies that can ever have, or may have had, a fund switch.\n",
    "## - This determines the list of products that allows us to determine the full switchable population at any time by identifying policies in force for any of the products found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38fa783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data\\iSuite_Product_list.csv\n"
     ]
    }
   ],
   "source": [
    "# READ IN directly from DW\n",
    "def iSuite_Product_list(server, database):\n",
    "    conn = pyodbc.connect(\n",
    "         'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "         'SERVER='+server+';'\n",
    "         'DATABASE='+database+';'\n",
    "         'Trusted_Connection=yes;')\n",
    "  \n",
    "    query = \"\"\"SELECT DISTINCT pol.Product_Code\n",
    "\t\t    FROM Unit_Transactions UT\n",
    "\t        INNER JOIN Fund F ON F.Fund_Code = UT.[Fund_Code]\n",
    "\t        INNER JOIN Policy pol ON pol.Policy_Number = UT.Policy_Number\n",
    "\t\t\tWHERE Transaction_Type = 'Funds Switch/Shift'\n",
    "\t\t\tAND\t((F.Asset_Type = 'UWP-Fonds' AND UWP_Type_Indicator = 'S') OR (F.Asset_Type <> 'UWP-Fonds' AND UWP_Type_Indicator = 'A')) \n",
    "\t\t\tAND Reverse_Indicator = 'N'\"\"\"    \n",
    "        \n",
    "    return pd.read_sql(query, conn)\n",
    "\n",
    "# Call the SQL proc to get a list of distinct iSuite product codes, \n",
    "# of products that have ever had a switch.\n",
    "df_iSuite_Product_list = iSuite_Product_list(SQL_server, Reporting_database)\n",
    "\n",
    "# Strip all blanks.\n",
    "df_iSuite_Product_list = df_iSuite_Product_list.applymap(lambda x: \" \".join(x.split()) if isinstance(x, str) else x)\n",
    "\n",
    "df_iSuite_Product_list.head(10)\n",
    "\n",
    "# Write out to a comma separated values file.\n",
    "filename = input_path + \"\\iSuite_Product_list.csv\"\n",
    "print(filename)\n",
    "\n",
    "df_iSuite_Product_list.to_csv(filename, encoding='utf-8', index=False)        \n",
    "\n",
    "# Turn off dislays to protect PII\n",
    "#df_iSuite_Product_list.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cb0049",
   "metadata": {},
   "source": [
    "# 2. Using the list of products which have had a switch, get details for all policies that can have switchable funds.\n",
    "## This is the population of policies that can possibly switch funds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0429f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8546822\n",
      "ContractNumber            object\n",
      "ProdCat                   object\n",
      "ProdCode                  object\n",
      "PolicyStatus              object\n",
      "CoverEndDt                object\n",
      "SnapshotDt        datetime64[ns]\n",
      "SnapshotYrMth             object\n",
      "dtype: object\n",
      ".\\data\\Full_Population.csv\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect(\n",
    "         'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "         'SERVER='+SQL_server+';'\n",
    "         'DATABASE='+Reporting_database+';'\n",
    "         'Trusted_Connection=yes;')\n",
    "\n",
    "main_query = f\"\"\"SELECT pol.Policy_Number         AS ContractNumber\n",
    "                       ,prd.Product_Category_Code AS ProdCat\n",
    "                       ,prd.Product_Code          AS ProdCode\n",
    "                       ,psh.Policy_Status_Code    AS PolicyStatus\n",
    "                       ,pol.Cover_End_Date        AS CoverEndDt\n",
    "                       ,psh.Snapshot_Date         AS SnapshotDt\n",
    "                 FROM Policy pol\n",
    "                 INNER JOIN Product prd ON prd.Product_Id = pol.Product_Id\n",
    "                 INNER JOIN Policy_Snapshot_Hist psh ON pol.Policy_Number = psh.Policy_Number \n",
    "                 WHERE prd.Product_Id = pol.Product_Id\n",
    "                 AND   prd.Product_Code IN ('FKP','XRPP')\n",
    "                 ORDER BY psh.Snapshot_Date,pol.Policy_Number;\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "df_main = pd.read_sql(main_query, conn)\n",
    "\n",
    "df_main['SnapshotDt'] = pd.to_datetime(df_main['SnapshotDt'])\n",
    "df_main['SnapshotYrMth'] = df_main['SnapshotDt'].dt.strftime('%Y%m')\n",
    "#df_main = df_main.drop(['SnapshotDt'],axis=1)\n",
    "\n",
    "# Types and row count\n",
    "print(len(df_main.index))\n",
    "print(df_main.dtypes)\n",
    "\n",
    "# Write out to a comma separated values file.\n",
    "filename = input_path + '\\Full_Population.csv'\n",
    "df_main.to_csv(filename, encoding='utf-8', index=False)        \n",
    "print(filename)\n",
    "\n",
    "# Turn off dislays to protect PII\n",
    "#df_main.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af5696e",
   "metadata": {},
   "source": [
    "# 3. Get the fund switch data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d22750a",
   "metadata": {},
   "source": [
    "## Get the Paxus fund switchesÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a40335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183962\n",
      "POLICY_NUMBER                     object\n",
      "LEGACY_FUND_CODE                  object\n",
      "PRODUCT                           object\n",
      "PROCESSING_DATE           datetime64[ns]\n",
      "EFFECTIVE_DATE            datetime64[ns]\n",
      "UNIT_TYPE                         object\n",
      "CHARGE_TYPE                       object\n",
      "CASH_VALUE                       float64\n",
      "RISK_COMMENCEMENT_DATE    datetime64[ns]\n",
      "Servicing_Broker_Code             object\n",
      "Issue_Date                datetime64[ns]\n",
      "Cover_End_Date            datetime64[ns]\n",
      "Anniversary_Date          datetime64[ns]\n",
      "Source                            object\n",
      "dtype: object\n",
      ".\\data\\All_Paxus_Switches.csv\n"
     ]
    }
   ],
   "source": [
    "# READ IN directly from Paxus\n",
    "def Get_All_Paxus_Switches(server, database):\n",
    "    conn = pyodbc.connect(\n",
    "         'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "         'SERVER='+server+';'\n",
    "         'DATABASE='+database+';'\n",
    "         'Trusted_Connection=yes;'\n",
    "         )\n",
    "\n",
    "    query = \"\"\"SELECT * FROM OPENQUERY(GERPDB,'\n",
    "    SELECT  p.policy            AS \"POLICY_NUMBER\",\n",
    "            u.fund              AS \"LEGACY_FUND_CODE\",\n",
    "            p.cov_cobe          AS \"PRODUCT\",\n",
    "            to_date(u.proc_date,''YYYYMMDD'') AS \"PROCESSING_DATE\",\n",
    "            to_date(u.eff_date,''YYYYMMDD'')  AS \"EFFECTIVE_DATE\",\n",
    "            u.unit_type                       AS \"UNIT_TYPE\",\n",
    "            u.charge_type                     AS \"CHARGE_TYPE\",\n",
    "            u.units_posted_cash               AS \"CASH_VALUE\",\n",
    "            to_date(p.rcd,''YYYYMMDD'')       AS \"RISK_COMMENCEMENT_DATE\",\n",
    "            p.agent                             AS \"Servicing_Broker_Code\",\n",
    "            to_date(p.issued_date,''YYYYMMDD'') AS \"Issue_Date\",\n",
    "            to_date(''19000101'',''YYYYMMDD'')  AS \"Cover_End_Date\",\n",
    "            to_date(''19000101'',''YYYYMMDD'')  AS \"Anniversary_Date\",\n",
    "            ''P''                               AS \"Source\"\n",
    "    FROM GERPDBA.UNIT u,gerpdba.policy p \n",
    "    WHERE p.policy = u.policy \n",
    "    AND u.trans_code = ''P135'' \n",
    "    AND to_date(u.proc_date,''YYYYMMDD'') > ''2018-12-31''\n",
    "    order by PROC_DATE, p.policy, u.fund\n",
    "    ')\"\"\"    \n",
    "    \n",
    "    \n",
    "    return pd.read_sql(query, conn)\n",
    "\n",
    "# Call the SQL process to retrieve the Paxus (old system) fund switch data.\n",
    "df_All_Paxus_Switches = Get_All_Paxus_Switches(SQL_server, Reporting_database)\n",
    "\n",
    "# Types and row count\n",
    "print(len(df_All_Paxus_Switches.index))\n",
    "print(df_All_Paxus_Switches.dtypes)\n",
    "\n",
    "# Write out to a comma separated values file.\n",
    "filename = input_path + '\\All_Paxus_Switches.csv'\n",
    "df_All_Paxus_Switches.to_csv(filename, encoding='utf-8', index=False)        \n",
    "print(filename)\n",
    "\n",
    "# Turn off dislays to protect PII\n",
    "#df_All_Paxus_Switches.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b25134",
   "metadata": {},
   "source": [
    "# 2. Get the iSuite fund switches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab58a828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18929\n",
      "POLICY_NUMBER              object\n",
      "LEGACY_FUND_CODE           object\n",
      "PRODUCT                    object\n",
      "PROCESSING_DATE            object\n",
      "EFFECTIVE_DATE             object\n",
      "UNIT_TYPE                  object\n",
      "CHARGE_TYPE                object\n",
      "CASH_VALUE                float64\n",
      "RISK_COMMENCEMENT_DATE     object\n",
      "Servicing_Broker_Code      object\n",
      "Issue_Date                 object\n",
      "Cover_End_Date             object\n",
      "Anniversary_Date           object\n",
      "Source                     object\n",
      "dtype: object\n",
      ".\\data\\All_iSuite_Switches.csv\n"
     ]
    }
   ],
   "source": [
    "def Get_All_iSuite_Switches(server, database):\n",
    "    conn = pyodbc.connect(        'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "        'SERVER='+server+';'\n",
    "        'DATABASE='+database+';'\n",
    "        'Trusted_Connection=yes;'  )\n",
    "\n",
    "    query_201 = \"\"\"Select \n",
    "\tFS_List.Policy_Number         AS \"POLICY_NUMBER\",\n",
    "\tLegacy_Fund_Code              AS \"LEGACY_FUND_CODE\",\n",
    "    PC.Product_Code               AS \"PRODUCT\",\n",
    "\tFS_List.Processing_Date       AS \"PROCESSING_DATE\",\n",
    "\tFS_List.Effective_Date        AS \"EFFECTIVE_DATE\",\n",
    "\tFS_List.Unit_Type             AS \"UNIT_TYPE\",\n",
    "    FS_List.Charge_Type           AS \"CHARGE_TYPE\",\n",
    "    Cash_Value                    AS \"CASH_VALUE\",\n",
    "\tPC.Risk_Commencement_Date     AS \"RISK_COMMENCEMENT_DATE\",\n",
    "    Servicing_Broker_Code,\n",
    "\tIssue_Date,\n",
    "    Cover_End_Date,\n",
    "    Anniversary_Date,\n",
    "    'I'                         AS \"Source\"\n",
    "\n",
    "FROM Policy_Core PC \n",
    "INNER JOIN (SELECT Policy_Number,\n",
    "\t\t           Transaction_Type,\n",
    "\t\t\t\t   UT.Processing_Date,\n",
    "\t\t\t\t   UT.Effective_Date,\n",
    "\t\t\t\t   UT.Unit_Type, \n",
    "\t\t\t\t   UT.Charge_Type,                    \n",
    "\t\t\t\t   Cash_Value,\n",
    "\t\t\t\t   F.Fund_Code,\n",
    "\t\t\t\t   F.Legacy_Fund_Code\n",
    "\t\t    FROM Unit_Transactions UT\n",
    "\t        INNER JOIN Fund F \n",
    "\t\t\tON F.Fund_Code = UT.[Fund_Code]\n",
    "\t\t\tWHERE Transaction_Type = 'Funds Switch/Shift'\n",
    "\t\t\tAND\t((F.Asset_Type = 'UWP-Fonds' AND UWP_Type_Indicator = 'S') OR (F.Asset_Type <> 'UWP-Fonds' AND UWP_Type_Indicator = 'A')) \n",
    "\t\t\tAND Reverse_Indicator = 'N') FS_LIST\n",
    "ON FS_LIST.[Policy_Number] = PC.Policy_Number\n",
    "WHERE FS_List.Processing_Date > '2018-12-31'\n",
    "ORDER BY Processing_Date,Policy_Number\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query_201, conn)\n",
    "\n",
    "# Call the SQL process to retrieve the Paxus (old system) fund switch data.\n",
    "df_All_iSuite_Switches = Get_All_iSuite_Switches(SQL_server, Reporting_database)\n",
    "\n",
    "# Types and row count\n",
    "print(len(df_All_iSuite_Switches.index))\n",
    "print(df_All_iSuite_Switches.dtypes)\n",
    "\n",
    "# Write out to a comma separated values file.\n",
    "filename = input_path + '\\All_iSuite_Switches.csv'\n",
    "df_All_iSuite_Switches.to_csv(filename, encoding='utf-8', index=False)      \n",
    "print(filename)\n",
    "\n",
    "# Turn off dislays to protect PII\n",
    "#df_All_iSuite_Switches.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a894391c",
   "metadata": {},
   "source": [
    "# Convert Paxus Cobes to Product Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac8568e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Product_Mapping(server, database):\n",
    "    conn = pyodbc.connect(\n",
    "        'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "        'SERVER='+server+';'\n",
    "        'DATABASE='+database+';'\n",
    "        'Trusted_Connection=yes;'\n",
    "        )\n",
    "\n",
    "    query_201 = \"Select * FROM Product_Mapping\"\n",
    "    return pd.read_sql(query_201, conn)\n",
    "\n",
    "# Call the SQL to get Paxus to iSuite product mappings.\n",
    "df_Product_Mapping = Get_Product_Mapping(SQL_server, Reference_Data_database)  \n",
    "\n",
    "# Strip all blanks.\n",
    "df_Product_Mapping = df_Product_Mapping.applymap(lambda x: \" \".join(x.split()) if isinstance(x, str) else x)\n",
    "\n",
    "# Turn off dislays to protect PII\n",
    "#df_Product_Mapping.head(99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4786b7",
   "metadata": {},
   "source": [
    "## Write out to a comma separated values file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "182d16bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data\\df_Product_Mapping.csv\n"
     ]
    }
   ],
   "source": [
    "# Write out to a comma separated values file.\n",
    "filename = input_path + '\\df_Product_Mapping.csv'\n",
    "df_Product_Mapping.to_csv(filename, encoding='utf-8', index=False)       \n",
    "print(filename)\n",
    "\n",
    "# Turn off dislays to protect PII\n",
    "#df_Product_Mapping.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f723f",
   "metadata": {},
   "source": [
    "## Join the Paxus switch to teh Paxus product mapping to make it have the same mapping as iSuite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07517631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the blanks from the product to allow them to join.\n",
    "df_All_Paxus_Switches['PRODUCT'] = df_All_Paxus_Switches['PRODUCT'].str.strip()\n",
    "\n",
    "# Join them\n",
    "df_All_Paxus_Switches_With_Product_Name = pd.merge(df_All_Paxus_Switches, df_Product_Mapping, left_on = ['PRODUCT'], right_on = ['Cobe_Code'] , how = 'left') \n",
    "\n",
    "# Turn off dislays to protect PII\n",
    "#df_All_Paxus_Switches_With_Product_Name.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a5abc7",
   "metadata": {},
   "source": [
    "## Clean the data and write to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2108c11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183962\n",
      "POLICY_NUMBER              object\n",
      "LEGACY_FUND_CODE           object\n",
      "PRODUCT                    object\n",
      "PROCESSING_DATE            object\n",
      "EFFECTIVE_DATE             object\n",
      "UNIT_TYPE                  object\n",
      "CHARGE_TYPE                object\n",
      "CASH_VALUE                float64\n",
      "RISK_COMMENCEMENT_DATE     object\n",
      "Servicing_Broker_Code      object\n",
      "Issue_Date                 object\n",
      "Cover_End_Date             object\n",
      "Anniversary_Date           object\n",
      "SOURCE                     object\n",
      "dtype: object\n",
      ".\\data\\All_Paxus_Switches_With_Product_Name.csv\n"
     ]
    }
   ],
   "source": [
    "# Remove unused columns after merge.\n",
    "df_All_Paxus_Switches_With_Product_Name = df_All_Paxus_Switches_With_Product_Name.drop(['PRODUCT','Cobe_Code'], axis=1)\n",
    "\n",
    "# Rename columns to match.\n",
    "df_All_Paxus_Switches_With_Product_Name = df_All_Paxus_Switches_With_Product_Name.rename(columns={\"Product_Code\":\"PRODUCT\"})\n",
    "df_All_Paxus_Switches_With_Product_Name = df_All_Paxus_Switches_With_Product_Name.rename(columns={\"Source\"      :\"SOURCE\"})\n",
    "\n",
    "# Reorder the data before the merge.\n",
    "neworder = ['POLICY_NUMBER','LEGACY_FUND_CODE','PRODUCT','PROCESSING_DATE','EFFECTIVE_DATE','UNIT_TYPE','CHARGE_TYPE','CASH_VALUE','RISK_COMMENCEMENT_DATE','Servicing_Broker_Code','Issue_Date','Cover_End_Date','Anniversary_Date','SOURCE']\n",
    "df_All_Paxus_Switches_With_Product_Name=df_All_Paxus_Switches_With_Product_Name.reindex(columns=neworder)\n",
    "\n",
    "# Example 1: Convert datetype to string\n",
    "df_All_Paxus_Switches_With_Product_Name['PROCESSING_DATE']=df_All_Paxus_Switches_With_Product_Name['PROCESSING_DATE'].astype(str)\n",
    "df_All_Paxus_Switches_With_Product_Name['EFFECTIVE_DATE']=df_All_Paxus_Switches_With_Product_Name['EFFECTIVE_DATE'].astype(str)\n",
    "df_All_Paxus_Switches_With_Product_Name['RISK_COMMENCEMENT_DATE']=df_All_Paxus_Switches_With_Product_Name['RISK_COMMENCEMENT_DATE'].astype(str)\n",
    "df_All_Paxus_Switches_With_Product_Name['Issue_Date']=df_All_Paxus_Switches_With_Product_Name['Issue_Date'].astype(str)\n",
    "df_All_Paxus_Switches_With_Product_Name['Cover_End_Date']=df_All_Paxus_Switches_With_Product_Name['Cover_End_Date'].astype(str)\n",
    "df_All_Paxus_Switches_With_Product_Name['Anniversary_Date']=df_All_Paxus_Switches_With_Product_Name['Anniversary_Date'].astype(str)\n",
    "\n",
    "\n",
    "# Types and row count\n",
    "print(len(df_All_Paxus_Switches_With_Product_Name.index))\n",
    "print(df_All_Paxus_Switches_With_Product_Name.dtypes)\n",
    "\n",
    "# Write out to a comma separated values file.\n",
    "filename = input_path + '\\All_Paxus_Switches_With_Product_Name.csv'\n",
    "print(filename)\n",
    "df_All_Paxus_Switches_With_Product_Name.to_csv(filename, encoding='utf-8', index=False)        \n",
    "\n",
    "# Turn off dislays to protect PII\n",
    "#df_All_Paxus_Switches_With_Product_Name.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28103376",
   "metadata": {},
   "source": [
    "# Merge all switches into one dataframe and write to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c78cd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202891\n",
      "index                       int64\n",
      "POLICY_NUMBER              object\n",
      "LEGACY_FUND_CODE           object\n",
      "PRODUCT                    object\n",
      "PROCESSING_DATE            object\n",
      "EFFECTIVE_DATE             object\n",
      "UNIT_TYPE                  object\n",
      "CHARGE_TYPE                object\n",
      "CASH_VALUE                float64\n",
      "RISK_COMMENCEMENT_DATE     object\n",
      "Servicing_Broker_Code      object\n",
      "Issue_Date                 object\n",
      "Cover_End_Date             object\n",
      "Anniversary_Date           object\n",
      "Source                     object\n",
      "SOURCE                     object\n",
      "dtype: object\n",
      ".\\data\\All_Switches.csv\n"
     ]
    }
   ],
   "source": [
    "# Merge the Paxus and iSuite switch data.\n",
    "df_All_Switches= df_All_iSuite_Switches.append(df_All_Paxus_Switches_With_Product_Name)\n",
    "\n",
    "# Soryt by policy number and processing date.\n",
    "df_All_Switches = df_All_Switches.sort_values(['PROCESSING_DATE','POLICY_NUMBER','SOURCE']).reset_index(drop=False)\n",
    "\n",
    "# Types and row count\n",
    "print(len(df_All_Switches.index))\n",
    "print(df_All_Switches.dtypes)\n",
    "\n",
    "# Write out to a comma separated values file.\n",
    "filename = input_path + '\\All_Switches.csv'\n",
    "df_All_Switches.to_csv(filename, encoding='utf-8', index=False)       \n",
    "print(filename)\n",
    "\n",
    "# Turn off dislays to protect PII\n",
    "#df_All_Switches.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9bc6940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_All_Paxus_Switches',\n",
       " 'df_All_Paxus_Switches_With_Product_Name',\n",
       " 'df_All_Switches',\n",
       " 'df_All_iSuite_Switches',\n",
       " 'df_Product_Mapping',\n",
       " 'df_iSuite_Product_list',\n",
       " 'df_main']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%who_ls DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fc53119",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_All_Paxus_Switches\n",
    "del df_All_Paxus_Switches_With_Product_Name\n",
    "del df_All_Switches\n",
    "del df_All_iSuite_Switches\n",
    "del df_Product_Mapping\n",
    "del df_iSuite_Product_list\n",
    "del df_main\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c6fbff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "2024-08-14 17:42:01.160677\n",
      "==========================\n",
      "svmem(total=16756752384, available=4605526016, percent=72.5, used=12151226368, free=4605526016)\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "print('==========================')\n",
    "now = datetime.now()\n",
    "print(now)\n",
    "print('==========================')\n",
    "print(psutil.virtual_memory())\n",
    "print('==========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c174e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
